# -*- coding: utf-8 -*-
"""CNN_train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K_GNq8x8S9PLcBAJebhBrCyENFq9mXGG
"""

import numpy as np
import pdb
import os
from tqdm import tqdm

from matplotlib import pyplot as plt

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.autograd import Variable
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
import torchvision
from torchvision.datasets import FashionMNIST
from torchvision import transforms
from sklearn.metrics import confusion_matrix
from utils import AverageMeter

class LeNet(nn.Module):

    def __init__(self):
        super(LeNet, self).__init__()
        self.cnn_model = nn.Sequential(
            nn.Conv2d(1, 6, kernel_size = 5), #(N, 1, 28, 28) -> (N, 6, 24, 24)
            nn.ReLU(),
            nn.AvgPool2d(2, stride = 2), #(N, 6, 24, 24) -> (N, 6, 12, 12)
            
            nn.Conv2d(6, 16, kernel_size = 5), #(N, 6, 12, 12) -> (N, 6, 8, 8)
            nn.ReLU(),
            nn.AvgPool2d(2, stride = 2)) #(N, 6, 8, 8) -> (N, 16, 4, 4)
    
        self.fc_model = nn.Sequential(
            nn.Linear(256, 120), # (N, 256) -> (N, 120)
            nn.ReLU(),
            nn.Linear(120, 84), # (N, 120) -> (N, 84)
            nn.ReLU(),
            nn.Linear(84, 10))  # (N, 84)  -> (N, 10))
            
    def forward(self, x):
        #print(x.shape)
        x = self.cnn_model(x)
        #print(x.shape)
        #print(x)
        x = x.view(x.size(0), -1)
        #print(x.shape)
        x = self.fc_model(x)
        #print(x.shape)
        return x
    ''' def __init__(self, n_classes=10):
        emb_dim = 20
        super(LeNet, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)
        self.emb = nn.Linear(64*7*7, emb_dim)
        self.clf = nn.Linear(emb_dim, n_classes)

    def num_flat_features(self, x):

        size = x.size()[1:]  # All dimensions except batch dimension
        num_features = 1
        for s in size:
            num_features *= s

        return num_features

    def forward(self, x):
        x = x.view(-1, 1, 28, 28)
        x = F.max_pool2d(F.relu(self.conv1(x)), 2)
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(-1, self.num_flat_features(x))
        x = self.emb(x)
        out = self.clf(x)

        return out'''

def train_one_epoch(model, trainloader, optimizer,valloader):
    """ Training the model using the given dataloader for 1 epoch.

    Input: Model, Dataset, optimizer, 
    """

    model.train()
    avg_loss = AverageMeter("average-loss")
    for batch_idx, (img, target) in enumerate(trainloader):
        img = Variable(img)#.to(device)
        target = Variable(target)#.to(device)

        if use_cuda and torch.cuda.is_available():
            img = img.cuda()
            target = target.cuda()

        # Zero out the gradients
        optimizer.zero_grad()
        # Forward Propagation
        prob = model(img)
        loss = F.cross_entropy(prob, target)

        # backward propagation
        loss.backward()
        avg_loss.update(loss, img.shape[0])

        # Update the model parameters
        optimizer.step()
    val_loss,acc,a,b=test(model,valloader,0)
    return avg_loss.avg,val_loss,acc

def test(model, testloader,flag):
    total=0
    correct=0
    model.eval()
    #model.to('cpu')
    avg_loss = AverageMeter("average-loss")

    y_gt = []
    y_pred_label = []

    for batch_idx, (img, y_true) in enumerate(testloader):
        img = Variable(img)#.to(device)
        y_true = Variable(y_true)#.to(device)
        if use_cuda and torch.cuda.is_available():
          img = img.cuda()
          y_true = y_true.cuda()

        out = model(img)
        y_pred = F.softmax(out, dim=1)
        y_pred_label_tmp = torch.argmax(y_pred, dim=1)

        loss = F.cross_entropy(out, y_true)
        avg_loss.update(loss, img.shape[0])

        # Add the labels
        if(flag==1):
          y_gt+= list(y_true.cpu().numpy())
          y_pred_label += list(y_pred_label_tmp.cpu().numpy())
        total+=y_true.size(0)
        correct+=(y_pred_label_tmp==y_true).sum()
    #model.to('cuda:0')
    return avg_loss.avg,(100 * correct / total),y_gt,y_pred_label

if __name__ == "__main__":

    number_epochs = 200
    use_cuda = False
    
    batch_size=1024
    # Use torch.device("cuda:0") if you want to train on GPU
    # OR Use torch.device("cpu") if you want to train on CPU
    #device = torch.device("cuda:0")

    model = LeNet()#.to(device)oss.item()
    if use_cuda and torch.cuda.is_available():
      model.cuda()

trans_img = transforms.Compose([transforms.ToTensor()])
dataset = FashionMNIST("./data/", train=True, transform=trans_img, download=True)

train_set,val_set=train_test_split(dataset,test_size=.20,random_state=7)

print(len(train_set))

trainloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)
valloader = DataLoader(val_set, batch_size=batch_size, shuffle=True)
optimizer = optim.Adam(model.parameters(), lr=0.001)

from google.colab import drive
drive.mount('/content/drive')

min_val_loss_epoch=(0,0,5) #acc,epoch,loss
track_loss = []
track_val_loss=[]
track_acc=[]
for i in tqdm(range(number_epochs)):
  loss,val_loss,acc= train_one_epoch(model, trainloader, optimizer,valloader)
  #print(torch.typename(loss))
  track_loss.append(loss.item())
  track_val_loss.append(val_loss.item())
  track_acc.append(acc)
  print('epoch:',i,'loss:',loss.item(),'val loss:',val_loss.item(),'acc:',acc.item())
  if(acc>min_val_loss_epoch[0]):
    min_val_loss_epoch=(acc.item(),i,val_loss.item())
    torch.save(model.state_dict(), "/content/drive/My Drive/convNet.pt")
    print('updated min:',val_loss.item(),'epoch:',i,'acc:',acc.item())
    #break;

plt.figure()
plt.plot(track_loss,'r')
plt.plot(track_val_loss,'g')
plt.ylabel('Loss')
plt.xlabel('Epochs')
#plt.plot(track_acc,'b')
plt.title("training(r), val-loss(g):convoNet")
#plt.title("training-loss-ConvNet")
plt.savefig("/content/drive/My Drive/training_convnet.jpg")

plt.figure()
plt.plot(track_loss,'b')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.title("training_loss:CNN")
#plt.title("training-loss-ConvNet")
plt.savefig("/content/drive/My Drive/rajat_training_convnet.jpg")

plt.figure()
plt.plot(track_acc,'b')
plt.title("Val_accuracy:convoNet")
plt.savefig("/content/drive/My Drive/training_convnet_acc.jpg")

test_dataset = FashionMNIST("./data/", train=False, transform=trans_img, download=True)

test_loader= DataLoader(test_dataset,batch_size=10,shuffle=True)

model = LeNet()
if use_cuda and torch.cuda.is_available():
      model.cuda()
model.load_state_dict(torch.load("/content/drive/My Drive/convNet.pt"))



loss_val,acc_val,a,b=test(model,valloader,0)
loss_train,acc_train,a,b=test(model,trainloader,0)
print('accuracy on val data:',acc_val.item())
print('accuracy on train data:',acc_train.item())
print('loss on val data:',loss_val.item())
print('loss on train data:',loss_train.item())
print('best val loss epochs:',min_val_loss_epoch[1],'acc:',min_val_loss_epoch[0])

loss_test,acc_test,a,b=test(model,valloader,1)

print('accuracy on test data:',acc_test.item())
print('loss on test data:',loss_test.item())

#print(len(a))
display_labels=list(range(10))

np.set_printoptions(formatter={'float_kind':'{:f}'.format})
cm=confusion_matrix(a,b,normalize='all')
#print(cm)

import seaborn as sn
import pandas as pd

#cm=np.array(cm,dtype='float32')
#cm=float(cm)

df_cm = pd.DataFrame(cm, index = display_labels,
                  columns = display_labels)
#df_cm.round(2)
plt.figure(figsize = (10,7))
sn.heatmap(df_cm, annot=True)
plt.savefig("/content/drive/My Drive/confusion_CNN.jpg")